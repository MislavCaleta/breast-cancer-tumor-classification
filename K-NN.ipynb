{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b364a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94297d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training and testing sets\n",
    "projectDirPath = os.path.abspath(\"\")\n",
    "\n",
    "X_train = pd.read_csv(projectDirPath + \"\\\\ready data\\\\X_train.csv\").values\n",
    "X_test = pd.read_csv(projectDirPath + \"\\\\ready data\\\\X_test.csv\").values\n",
    "y_train = pd.read_csv(projectDirPath + \"\\\\ready data\\\\y_train.csv\").values.reshape(-1,)\n",
    "y_test = pd.read_csv(projectDirPath + \"\\\\ready data\\\\y_test.csv\").values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f9b3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the models (3 models with different number of neighbors)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn2 = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn3 = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn1.fit(X_train, y_train)\n",
    "knn2.fit(X_train, y_train)\n",
    "knn3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b21251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 neighbors:\n",
      "mean of 10 accuracies1:  0.9751088534107403\n",
      "standard deviation of accuracies1:  0.05106840454882057\n",
      "mean of 10 recalls1:  0.9751088534107403\n",
      "standard deviation of recalls1:  0.05106840454882057 \n",
      "\n",
      "4 neighbors:\n",
      "mean of 10 accuracies2:  0.9674528301886791\n",
      "standard deviation of accuracies2:  0.06526169064983801\n",
      "mean of 10 recalls2:  0.9674528301886791\n",
      "standard deviation of recalls2:  0.06526169064983801 \n",
      "\n",
      "5 neighbors:\n",
      "mean of 10 accuracies3:  0.9731857764876632\n",
      "standard deviation of accuracies3:  0.0370596012111225\n",
      "mean of 10 recalls3:  0.9731857764876632\n",
      "standard deviation of recalls3:  0.0370596012111225\n"
     ]
    }
   ],
   "source": [
    "#validation of the models using k-cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "\n",
    "accuracies1 = cross_val_score(estimator = knn1, X = X_train, y = y_train, cv = 10)\n",
    "accuracies2 = cross_val_score(estimator = knn2, X = X_train, y = y_train, cv = 10)\n",
    "accuracies3 = cross_val_score(estimator = knn3, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "recall_scorer = make_scorer(recall_score, pos_label = 4)\n",
    "recalls1 = cross_val_score(estimator = knn1, X = X_train, y = y_train, cv = 10, scoring = recall_scorer)\n",
    "recalls2 = cross_val_score(estimator = knn2, X = X_train, y = y_train, cv = 10, scoring = recall_scorer)\n",
    "recalls3 = cross_val_score(estimator = knn3, X = X_train, y = y_train, cv = 10, scoring = recall_scorer)\n",
    "\n",
    "accMean1 = accuracies1.mean()\n",
    "accStdDev1 = accuracies1.std()\n",
    "recMean1 = recalls1.mean()\n",
    "recStdDev1 = recalls1.std()\n",
    "print(\"3 neighbors:\\nmean of 10 accuracies1: \", accMean1)\n",
    "print(\"standard deviation of accuracies1: \", recStdDev1)\n",
    "print(\"mean of 10 recalls1: \", accMean1)\n",
    "print(\"standard deviation of recalls1: \", recStdDev1, \"\\n\")\n",
    "\n",
    "accMean2 = accuracies2.mean()\n",
    "accStdDev2 = accuracies2.std()\n",
    "recMean2 = recalls2.mean()\n",
    "recStdDev2 = recalls2.std()\n",
    "print(\"4 neighbors:\\nmean of 10 accuracies2: \", accMean2)\n",
    "print(\"standard deviation of accuracies2: \", recStdDev2)\n",
    "print(\"mean of 10 recalls2: \", accMean2)\n",
    "print(\"standard deviation of recalls2: \", recStdDev2, \"\\n\")\n",
    "\n",
    "accMean3 = accuracies3.mean()\n",
    "accStdDev3 = accuracies3.std()\n",
    "recMean3 = recalls3.mean()\n",
    "recStdDev3 = recalls3.std()\n",
    "print(\"5 neighbors:\\nmean of 10 accuracies3: \", accMean3)\n",
    "print(\"standard deviation of accuracies3: \", recStdDev3)\n",
    "print(\"mean of 10 recalls3: \", accMean3)\n",
    "print(\"standard deviation of recalls3: \", recStdDev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3068140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 neighbors:\n",
      "accuracy1 on the test set:  0.9542857142857143\n",
      "recall1 on the test set:  0.9310344827586207\n",
      "confusion matrix1:\n",
      "  [[113   4]\n",
      " [  4  54]] \n",
      "\n",
      "4 neighbors:\n",
      "accuracy2 on the test set:  0.9428571428571428\n",
      "recall2 on the test set:  0.8793103448275862\n",
      "confusion matrix2:\n",
      "  [[114   3]\n",
      " [  7  51]] \n",
      "\n",
      "5 neighbors:\n",
      "accuracy3 on the test set:  0.96\n",
      "recall3 on the test set:  0.9482758620689655\n",
      "confusion matrix3:\n",
      "  [[113   4]\n",
      " [  3  55]]\n"
     ]
    }
   ],
   "source": [
    "#testing of the models on the test set and computing : accuracy, recall and confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_pred1 = knn1.predict(X_test)\n",
    "y_pred2 = knn2.predict(X_test)\n",
    "y_pred3 = knn3.predict(X_test)\n",
    "\n",
    "acc1 = accuracy_score(y_test, y_pred1)\n",
    "acc2 = accuracy_score(y_test, y_pred2)\n",
    "acc3 = accuracy_score(y_test, y_pred3)\n",
    "\n",
    "rec1 = recall_score(y_test, y_pred1, pos_label = 4)\n",
    "rec2 = recall_score(y_test, y_pred2, pos_label = 4)\n",
    "rec3 = recall_score(y_test, y_pred3, pos_label = 4)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred1)\n",
    "cm2 = confusion_matrix(y_test, y_pred2)\n",
    "cm3 = confusion_matrix(y_test, y_pred3)\n",
    "\n",
    "print(\"3 neighbors:\\naccuracy1 on the test set: \", acc1)\n",
    "print(\"recall1 on the test set: \", rec1)\n",
    "print(\"confusion matrix1:\\n \", cm1, \"\\n\")\n",
    "\n",
    "print(\"4 neighbors:\\naccuracy2 on the test set: \", acc2)\n",
    "print(\"recall2 on the test set: \", rec2)\n",
    "print(\"confusion matrix2:\\n \", cm2, \"\\n\")\n",
    "\n",
    "print(\"5 neighbors:\\naccuracy3 on the test set: \", acc3)\n",
    "print(\"recall3 on the test set: \", rec3)\n",
    "print(\"confusion matrix3:\\n \", cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfbdbbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\misla\\\\Desktop\\\\breast cancer tumor classification\\\\models\\\\K-NN.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the valid model based on highest recall\n",
    "from joblib import dump\n",
    "\n",
    "dump(knn3, projectDirPath + \"\\\\models\\\\K-NN.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "416b9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving evaluation data for all tried out models\n",
    "import json\n",
    "\n",
    "knn1Data = {\"mean10Acc\" : accMean1, \"accStd\" : accStdDev1, \"mean10Rec\" : recMean1, \"recStd\" : recStdDev1, \"acc\": acc1, \"rec\": rec1}\n",
    "knn2Data = {\"mean10Acc\" : accMean2, \"accStd\" : accStdDev2, \"mean10Rec\" : recMean2, \"recStd\" : recStdDev2, \"acc\": acc2, \"rec\": rec2}\n",
    "knn3Data = {\"mean10Acc\" : accMean3, \"accStd\" : accStdDev3, \"mean10Rec\" : recMean3, \"recStd\" : recStdDev3, \"acc\": acc3, \"rec\": rec3}\n",
    "evalData = [knn1Data, knn2Data, knn3Data]\n",
    "\n",
    "cmData1 = {\"tn\" : int(cm1[0, 0]), \"fn\" : int(cm1[1, 0]), \"tp\" : int(cm1[1, 1]), \"fp\" : int(cm1[0, 1])}\n",
    "cmData2 = {\"tn\" : int(cm2[0, 0]), \"fn\" : int(cm2[1, 0]), \"tp\" : int(cm2[1, 1]), \"fp\" : int(cm2[0, 1])}\n",
    "cmData3 = {\"tn\" : int(cm3[0, 0]), \"fn\" : int(cm3[1, 0]), \"tp\" : int(cm3[1, 1]), \"fp\" : int(cm3[0, 1])}\n",
    "cmData = [cmData1, cmData2, cmData3]\n",
    "\n",
    "i = 1\n",
    "for data in evalData:\n",
    "    with open(projectDirPath + \"\\\\modelsData\\\\knn{}.json\".format(i), \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "    i += 1\n",
    "\n",
    "i = 1\n",
    "for data in cmData:\n",
    "    with open(projectDirPath + \"\\\\modelsData\\\\knn{}Cm.json\".format(i), \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a82386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
